import{s as pi,n as bt}from"../chunks/scheduler.63274e7e.js";import{S as mi,i as fi,g as n,s as r,m as N,H as We,h as s,z as a,c as u,j as m,n as z,B as Ne,f as i,k as y,a as l,y as o}from"../chunks/index.d9809aad.js";function bi(ri){let f,gt="Publish Database from ERD",me,x,vt=`I’m focusing here only on a relational database, typically a suitable choice for my use cases.<br/>
I often find that blogs/tutorials/demos always skip over the data aspect of solutions.<br/>
In my experience managing code is easy, managing data is hard.  Unless your data is transient in nature database changes require careful thought.`,fe,C,wt="My key requirements in an effective data design strategy are:",be,q,yt=`<li><strong>Visualisation</strong> - I want to see an ERD or something similar, without this understanding a non-trivial database is going to be hard.<br/>
This needs to be versioned with the code, which rules out Visio and other binary representations.</li> <li><strong>Automation</strong> - The ERD and the production database should be linked via automated means.<br/>
Out-of-date documentation is sometimes worse than no documentation at all.<br/>
This rules out EF Core migrations (even if not using EF Core for production code).</li> <li><strong>Testability</strong> - Not so much a feature of the database, but I need to know that DB changes do not break things.<br/>
This means that integration tests must use the real database, on the same version as production, also during local dev, which leads me towards Docker.</li> <li><strong>Provider-agnostic</strong> - I have seen what vendor lock-in leads to and I don’t like it, we must maintain control of our applications.<br/>
In reality it is impossible to avoid this completely, but simple things like adhering to <a href="https://learnsql.com/blog/history-of-sql-standards/" rel="nofollow">SQL Standards</a> can help reduce the impact of migration.  I only want tables, indexes, constraints and possibly views, all logic will be in the application code.
This requirement rules out SSDT and <a href="https://github.com/microsoft/DacFx" rel="nofollow">DACPAC</a> deployment which is great, but only for SQL Server.</li> <li><strong>Maintainability</strong> - the solution needs to be simple to use in the medium to long term, though not necessarily simple to set up.</li>`,ge,L,xt="This mini project is something I’ve been meaning to do for years, since I built an Oracle DB deployment tool in Go and subsequently discovered DACPAC deployment in SQL Server.",ve,T,Ct="Visualisation",we,_,qt=`I considered various options, including Microsoft Visio, <a href="https://mermaid.js.org/syntax/entityRelationshipDiagram.html" rel="nofollow">Mermaid</a>, <a href="https://dbdiagram.io/home/" rel="nofollow">dbdiagram.io</a>, <a href="https://structurizr.com/dsl?example=getting-started" rel="nofollow">Structurizr</a> to generate Mermaid diagrams, but eventually settled on <a href="https://marketplace.visualstudio.com/items?itemName=dineug.vuerd-vscode" rel="nofollow">ERD Editor</a> for VS Code.<br/>
I came to this decision because:`,ye,S,Lt="<li>It is free &amp; open source, so even if it was taken offline and destroyed I could invest some time and recover to my forked version</li> <li>It is offline, meaning that any sensitive data models are kept secure</li> <li>It is stored in text/json format, not binary, which makes version control in git tenable</li> <li>It has a feature to output liquibase changelogs built in</li>",xe,k,Tt="Automation",Ce,I,_t=`Most DB automation tools are either prohibitively expensive, or vendor-specific.<br/>
I considered various options for automation, including:`,qe,M,St='<li>Enhancing my old Go based solution for Oracle DBs, but I don’t have the code, only the design principles, so effectively this would be a fresh start.</li> <li><a href="https://learn.microsoft.com/en-us/sql/ssdt/extract-publish-and-register-dacpac-files?view=sql-server-ver16" rel="nofollow">SSDT (DACPAC publish)</a>, but this is SQL Server specific.</li> <li><a href="https://learn.microsoft.com/en-us/ef/core/managing-schemas/migrations/?tabs=dotnet-core-cli" rel="nofollow">EF Migrations</a>, but this doesn’t work with visualisation tools AFAIK and I don’t want to be tied to EF Core, since it is .NET only.</li> <li><a href="https://www.red-gate.com/solutions/need/automate" rel="nofollow">Redgate Tools</a> but I assume this is too expensive since they don’t list the price on their website.</li> <li><a href="https://fluentmigrator.github.io" rel="nofollow">Fluent Migrator</a> but again this is .NET-specific, I don’t see a benefit over EF Core.</li> <li><a href="https://github.com/chucknorris/roundhouse/wiki" rel="nofollow">Roundhouse</a> but again this is .NET-specific, it also seems to be poorly maintained although I do like the convention-over-configuration approach at a glance</li>',Le,H,kt='I eventually settled on <a href="https://www.liquibase.com/download" rel="nofollow">Liquibase</a> because it has a free and open source option (Apache-2.0 licensed), supports Docker, is clearly built to support CI/CD with documented <a href="https://docs.liquibase.com/workflows/liquibase-community/home.html" rel="nofollow">Open Source Workflows</a> and, crucially, it works with the visualisation tool I’ve selected.',Te,D,It="Testability",_e,E,Mt=`The prompt for this mini-project was the discovery of <a href="https://github.com/testcontainers" rel="nofollow">Testcontainers</a> (via Nick Chapsas on Youtube).<br/>
This allows you to spin up a throwaway docker container, or collection of, just for the lifetime of the test(s).<br/>
This is not a substitute for unit testing since it will be significantly slower, but it is a better solution than testing with in-memory databases, which may have subtle differences in behaviour to the production database.`,Se,F,Ht="The solution",ke,P,Dt="Initial setup",Ie,c,U,Et="Install Docker (and optionally Docker Desktop, if licencing allows), examples below are unix images on Windows.",ze,G,Ft="Run SQL instance (example is MSSQL) for any manual testing and to prove scripts<br/> <code>docker run --name &quot;mssql_manual_test&quot; -e &quot;ACCEPT_EULA=Y&quot; -e &quot;MSSQL_SA_PASSWORD=yourStrong(!)Password&quot; -p 1433:1433 -d mcr.microsoft.com/mssql/server:2022-latest</code>",Ue,V,Pt="Get latest liquibase image <code>docker pull liquibase/liquibase</code>",Ge,K,At="Install VS Code extension “ERD Editor” (vuerd)",Ve,Y,Rt="Create an ERD file <code>&lt;name&gt;.vuerd.json</code> within the project/solution/workspace, open this in VS Code and it should automatically load the editor.",Ke,J,Bt=`Create a DB model, be sure not to deselect Postgres as the output regardless of target DB type, required for Liquibase support<br/>
Be careful here to use appropriate data types for the target environment, <a href="https://github.com/dineug/erd-editor/blob/master/packages/sql-ddl-parser/src/SQL_DDL_Test_Case.md" rel="nofollow">ERD Editor supported types</a>.<br/>
The tool is clever enough to convert from <code>uuid</code> to <code>uniqueidentifier</code>, but not clever enough to convert from <code>varchar</code> to <code>varchar2</code> for example and certainly not when lengths are included (which they need to be since the default is 1 character).<br/>
Effectively I’d advise making multiple DB models if supporting multiple DB providers, but decide which is master, copy/paste, find/replace in JSON files to keep multiple versions in sync and versioned together (this is why models should be stored in text format).`,Ye,$,Qt=`Generate a Liquibase changeset by right clicking the model and selecting Export &gt; Liquibase<br/>
Use the naming convention <em>liquibase-change-###</em>, 999 DB changes should be enough for most projects.<br/>
Liquibase uses the id, author and filename to track changes - <a href="https://www.liquibase.com/how-liquibase-works" rel="nofollow">How Liquibase works</a><br/>
Keep the changelogs alongside the ERD model in source code, this lets ERD Editor load older changelogs to guarantee correct generation of new changelogs.<br/>
To apply multiple chainsets automatically, which we will need for automation, it is necessary to manually configure a master changelog <code>liquibase-change.xml</code>.`,Je,d,$e,X,jt="liquibase.properties",Xe,Z,Me,ui=`<code class="language-undefined">classpath: /liquibase/changelog
changeLogFile: changelog.xml
url: jdbc:sqlserver://localhost:1433;database=master;encrypt=true;trustServerCertificate=true
username: sa
password: yourStrong(!)Password
# liquibaseProLicenseKey=&lt;PASTE LB PRO LICENSE KEY HERE&gt;</code>`,Ze,g,Ot="SQL Server docker",et,v,Wt="Liquibase recommendation",tt,it,ot,ee,Nt="encrypt=true and trustServerCertificate=true",nt,st,te,zt="We can now run liquibase commands, e.g. help<br/> <code>docker run --rm --net=host -v &quot;C:\\Path\\To\\Folder\\Containing\\changelogs&quot;:/liquibase/changelog liquibase/liquibase --defaultsFile=/liquibase/changelog/liquibase.properties --help</code><br/> <code>--rm</code> ensures that the docker container is removed after completion of the script (see debugging)<br/> <code>-net=host</code> ensures that the liquibase container can talk outside of the Docker bridge network (e.g. to connect to a Docker hosted DB).  In hindsight it is better to use internal network alias on the SQL container to connect from liquibase.<br/> <code>-v</code> maps our local folder (Windows in this example) to the root of Liquibase’s changelog tree volume.<br/> <code>--defaultsFile</code> tells Liquibase to use our properties file, which in turn tells it where to find changelogs and how to connect to the DB.<br/> <code>--help</code> tells Liquibase to show us its help documentation, including available commands",lt,ie,Ut=`Debugging - if any of our commands fail we can investigate by launching Liquibase with a built-in in-memory DB:<br/> <code>docker run --net=host -v &quot;C:\\Path\\To\\Folder\\Containing\\changelogs&quot;:/liquibase/changelog liquibase/liquibase --defaultsFile=/liquibase/changelog/liquibase.properties init start-h2</code><br/>
In a separate command window find the running container using <code>docker ps</code><br/>
Jump inside it using <code>docker exec -it &lt;container_id&gt; bash</code>, you should see your files within <code>/changelog</code><br/>
From here you can run the same commands (everything after liquibase/liquibase) on top of liquibase directly, e.g. <code>liquibase --help</code><br/>
When done you will need to stop and remove the docker container yourself.`,at,oe,Gt=`Apply the changeset to the database manually (dbo schema is default for SQL Server)<br/> <code>docker run --rm --net=host -v &quot;C:\\Path\\To\\Folder\\Containing\\changelogs&quot;:/liquibase/changelog liquibase/liquibase --defaultsFile=/liquibase/changelog/liquibase.properties update --changelog-file=liquibase-change-001.xml --default-schema-name=dbo</code><br/>
If a changeset fails in dev, perhaps due to messing up constraints :|, and you wish to keep changesets clean before commit, you can truncate the table DATABASECHANGELOG which Liquibase manages.`,rt,ne,Vt="Check that this has worked as expected using SQL Server Object Explorer in Visual Studio or SQL browser of preference.",He,A,Kt="Code changes",De,p,R,se,Yt="Ensure that any DB code (repository) accesses the connection string via <code>IOptions</code> or better yet <code>IOptionsSnapshot</code> to allow live reloading of config.",ut,le,Ee,ci=`<code class="language-c#">public class ConnectionStringsOptions
&#123;
   public const string ConfigKey = &quot;ConnectionStrings&quot;;
   public string MyDb &#123; get; set; &#125; = string.Empty;
&#125;</code>`,ct,ae,Jt=`<p>Create an xUnit IClassFixture <code>MsSqlTestFixture</code>, implementing <code>IAsyncLifetime</code> to ensure that it runs once per test class which uses it.<br/>
This class will:</p> <ol><li>Create a SQL container using the <code>ContainerBuilder</code>, mirroring the parameters above, although with a dynamically generated port.</li> <li>Wait for this to become responsive (by which I mean can accept SQL commands not just commands at the Docker/network layer)</li> <li>Spin up a Liquibase container to run a single command on this transient database - <code>update</code>, to apply all changes to get to the current version from an empty database and dispose it after completion.</li> <li>Expose SQL connection details via internal constants, for use by the test application.</li> <li>Dispose the SQL container and associated classes after test execution.</li></ol>`,dt,b,re,$t=`Create a custom <code>WebApplicationFactory</code> for testing, e.g. <code>TestWebApplicationFactory</code>.<br/>
This class will:`,ht,ue,Xt="<li>Start with the WebApplicationFactory used by the application itself.</li> <li>Replace real external dependencies in favour of managed stubs/fakes (out of scope of this document).</li> <li>Use constructor injection to load the SQL TestFixture which exposes the connection details of the transient database.</li> <li>Replace real connection strings with a connection string built from the SQL container settings.</li>",pt,ce,Fe,di=`<code class="language-c#">public TestWebApplicationFactory(MsSqlTestFixture sqlTestFixture)
&#123;
 _connectionString = $&quot;Server=&#123;sqlTestFixture._msSqlcontainer.Hostname
     &#125;,&#123;sqlTestFixture._msSqlcontainer.GetMappedPublicPort(MsSqlTestFixture.MsSqlPort)
     &#125;;Database=&#123;MsSqlTestFixture.Database
     &#125;;User Id=&#123;MsSqlTestFixture.Username
     &#125;;Password=&#123;MsSqlTestFixture.Password
     &#125;;TrustServerCertificate=True&quot;;
&#125;

protected override IHost CreateHost(IHostBuilder builder)
&#123;
   builder.ConfigureServices(services =&gt; 
   &#123;
      services.Configure&lt;ConnectionStringsOptions&gt;(opts =&gt; &#123;
      opts.MyDb = _connectionString;
      &#125;);
   &#125;);
&#125;</code>`,mt,B,de,Zt=`Create a test class <code>MsSqlTests</code> which inherits <code>IClassFixture&lt;MsSqlTestFixture&gt;</code> and <code>IDisposable</code><br/>
In the constructor use the above classes to make the DB available to the tests:`,ft,he,Pe,hi=`<code class="language-c#">public MsSqlTests(MsSqlTestFixture msSqlTestFixture)
&#123;
   _webApplicationFactory = new TestWebApplicationFactory&lt;Program&gt;(msSqlTestFixture);
   _httpClient = _webApplicationFactory.CreateClient(new WebApplicationFactoryClientOptions &#123;
     AllowAutoRedirect = false // Test first response
   &#125;);
&#125;
public void Dispose()
&#123;
   _webApplicationFactory.Dispose();
&#125;</code>`,Ae,Q,ei="Issues",Re,j,ti=`It takes some time to spin up a liquibase container, connect to a SQL database and apply migration scripts.<br/>
I found during exploration that whilst debugging the test everything was working as designed, however, whilst running the tests had completed (with failures) before the DB scripts had been executed.<br/>
It is possible to set a WaitStrategy on testcontainers to ensure that they are ready before moving on.<br/>
I had no luck getting this to work with liquibase, since it is not designed to stay up after the command is completed.<br/>
I’m sure there’s a better way, but my fix for this was to put a while loop in between starting and disposing the liquibase container.<br/>
This simply runs an appropriate query on the SQL container which indicates completion, then waits for a second before retrying, up to N times.`,Be,O,ii="Next steps",Qe,W,oi=`The solution now works as intended (as long as you remember to start Docker first).<br/>
I simply need to complete the work now, in a more test driven fashion than I normally would.<br/>
Finally I need to automate integration testing on CICD pipelines.<br/>
All of the above is checked in to a private GitHub repo for now, I may make this public at some point.`;return{c(){f=n("h1"),f.textContent=gt,me=r(),x=n("p"),x.innerHTML=vt,fe=r(),C=n("p"),C.textContent=wt,be=r(),q=n("ol"),q.innerHTML=yt,ge=r(),L=n("p"),L.textContent=xt,ve=r(),T=n("h2"),T.textContent=Ct,we=r(),_=n("p"),_.innerHTML=qt,ye=r(),S=n("ul"),S.innerHTML=Lt,xe=r(),k=n("h2"),k.textContent=Tt,Ce=r(),I=n("p"),I.innerHTML=_t,qe=r(),M=n("ul"),M.innerHTML=St,Le=r(),H=n("p"),H.innerHTML=kt,Te=r(),D=n("h2"),D.textContent=It,_e=r(),E=n("p"),E.innerHTML=Mt,Se=r(),F=n("h2"),F.textContent=Ht,ke=r(),P=n("h3"),P.textContent=Dt,Ie=r(),c=n("ol"),U=n("li"),U.textContent=Et,ze=r(),G=n("li"),G.innerHTML=Ft,Ue=r(),V=n("li"),V.innerHTML=Pt,Ge=r(),K=n("li"),K.textContent=At,Ve=r(),Y=n("li"),Y.innerHTML=Rt,Ke=r(),J=n("li"),J.innerHTML=Bt,Ye=r(),$=n("li"),$.innerHTML=Qt,Je=r(),d=n("li"),$e=N("Configure liquibase using a "),X=n("em"),X.textContent=jt,Xe=N(" file in the same folder:  "),Z=n("pre"),Me=new We(!1),Ze=N("This example is using the defaults for a "),g=n("a"),g.textContent=Ot,et=N(" container, although the "),v=n("a"),v.textContent=Wt,tt=N(" is to pass these as arguments.  Passing by argument is also required for running multiple test sets in parallel since only one Docker container at a time can respond on a given port, even if we reuse credentials for testing, so this defaultsFile is kept just to simplify any manual test processes locally."),it=n("br"),ot=N(`
We require `),ee=n("code"),ee.textContent=Nt,nt=N(" to resolve firewall and SSL errors respectively, encountered whilst applying test changeset."),st=r(),te=n("li"),te.innerHTML=zt,lt=r(),ie=n("li"),ie.innerHTML=Ut,at=r(),oe=n("li"),oe.innerHTML=Gt,rt=r(),ne=n("li"),ne.textContent=Vt,He=r(),A=n("h3"),A.textContent=Kt,De=r(),p=n("ol"),R=n("li"),se=n("p"),se.innerHTML=Yt,ut=r(),le=n("pre"),Ee=new We(!1),ct=r(),ae=n("li"),ae.innerHTML=Jt,dt=r(),b=n("li"),re=n("p"),re.innerHTML=$t,ht=r(),ue=n("ol"),ue.innerHTML=Xt,pt=r(),ce=n("pre"),Fe=new We(!1),mt=r(),B=n("li"),de=n("p"),de.innerHTML=Zt,ft=r(),he=n("pre"),Pe=new We(!1),Ae=r(),Q=n("h3"),Q.textContent=ei,Re=r(),j=n("p"),j.innerHTML=ti,Be=r(),O=n("h3"),O.textContent=ii,Qe=r(),W=n("p"),W.innerHTML=oi,this.h()},l(e){f=s(e,"H1",{"data-svelte-h":!0}),a(f)!=="svelte-tkkn75"&&(f.textContent=gt),me=u(e),x=s(e,"P",{"data-svelte-h":!0}),a(x)!=="svelte-r9hd"&&(x.innerHTML=vt),fe=u(e),C=s(e,"P",{"data-svelte-h":!0}),a(C)!=="svelte-1pt0bux"&&(C.textContent=wt),be=u(e),q=s(e,"OL",{"data-svelte-h":!0}),a(q)!=="svelte-13wui0b"&&(q.innerHTML=yt),ge=u(e),L=s(e,"P",{"data-svelte-h":!0}),a(L)!=="svelte-1szsvn9"&&(L.textContent=xt),ve=u(e),T=s(e,"H2",{"data-svelte-h":!0}),a(T)!=="svelte-1qdhikx"&&(T.textContent=Ct),we=u(e),_=s(e,"P",{"data-svelte-h":!0}),a(_)!=="svelte-1dfveau"&&(_.innerHTML=qt),ye=u(e),S=s(e,"UL",{"data-svelte-h":!0}),a(S)!=="svelte-1nu6zh1"&&(S.innerHTML=Lt),xe=u(e),k=s(e,"H2",{"data-svelte-h":!0}),a(k)!=="svelte-1q7hrmx"&&(k.textContent=Tt),Ce=u(e),I=s(e,"P",{"data-svelte-h":!0}),a(I)!=="svelte-1tunn2c"&&(I.innerHTML=_t),qe=u(e),M=s(e,"UL",{"data-svelte-h":!0}),a(M)!=="svelte-1al8qoz"&&(M.innerHTML=St),Le=u(e),H=s(e,"P",{"data-svelte-h":!0}),a(H)!=="svelte-1wnt3np"&&(H.innerHTML=kt),Te=u(e),D=s(e,"H2",{"data-svelte-h":!0}),a(D)!=="svelte-8313lo"&&(D.textContent=It),_e=u(e),E=s(e,"P",{"data-svelte-h":!0}),a(E)!=="svelte-13dx9zw"&&(E.innerHTML=Mt),Se=u(e),F=s(e,"H2",{"data-svelte-h":!0}),a(F)!=="svelte-fem3ok"&&(F.textContent=Ht),ke=u(e),P=s(e,"H3",{"data-svelte-h":!0}),a(P)!=="svelte-64imnl"&&(P.textContent=Dt),Ie=u(e),c=s(e,"OL",{});var t=m(c);U=s(t,"LI",{"data-svelte-h":!0}),a(U)!=="svelte-okopo3"&&(U.textContent=Et),ze=u(t),G=s(t,"LI",{"data-svelte-h":!0}),a(G)!=="svelte-bj3vwi"&&(G.innerHTML=Ft),Ue=u(t),V=s(t,"LI",{"data-svelte-h":!0}),a(V)!=="svelte-1d1vsnw"&&(V.innerHTML=Pt),Ge=u(t),K=s(t,"LI",{"data-svelte-h":!0}),a(K)!=="svelte-12cnoci"&&(K.textContent=At),Ve=u(t),Y=s(t,"LI",{"data-svelte-h":!0}),a(Y)!=="svelte-wwwrwd"&&(Y.innerHTML=Rt),Ke=u(t),J=s(t,"LI",{"data-svelte-h":!0}),a(J)!=="svelte-1b81auz"&&(J.innerHTML=Bt),Ye=u(t),$=s(t,"LI",{"data-svelte-h":!0}),a($)!=="svelte-1vljfo5"&&($.innerHTML=Qt),Je=u(t),d=s(t,"LI",{});var h=m(d);$e=z(h,"Configure liquibase using a "),X=s(h,"EM",{"data-svelte-h":!0}),a(X)!=="svelte-zuyoau"&&(X.textContent=jt),Xe=z(h," file in the same folder:  "),Z=s(h,"PRE",{class:!0});var ni=m(Z);Me=Ne(ni,!1),ni.forEach(i),Ze=z(h,"This example is using the defaults for a "),g=s(h,"A",{href:!0,rel:!0,"data-svelte-h":!0}),a(g)!=="svelte-1wl82bc"&&(g.textContent=Ot),et=z(h," container, although the "),v=s(h,"A",{href:!0,rel:!0,"data-svelte-h":!0}),a(v)!=="svelte-1erdglk"&&(v.textContent=Wt),tt=z(h," is to pass these as arguments.  Passing by argument is also required for running multiple test sets in parallel since only one Docker container at a time can respond on a given port, even if we reuse credentials for testing, so this defaultsFile is kept just to simplify any manual test processes locally."),it=s(h,"BR",{}),ot=z(h,`
We require `),ee=s(h,"CODE",{"data-svelte-h":!0}),a(ee)!=="svelte-ztbupi"&&(ee.textContent=Nt),nt=z(h," to resolve firewall and SSL errors respectively, encountered whilst applying test changeset."),h.forEach(i),st=u(t),te=s(t,"LI",{"data-svelte-h":!0}),a(te)!=="svelte-bp05u8"&&(te.innerHTML=zt),lt=u(t),ie=s(t,"LI",{"data-svelte-h":!0}),a(ie)!=="svelte-19264jc"&&(ie.innerHTML=Ut),at=u(t),oe=s(t,"LI",{"data-svelte-h":!0}),a(oe)!=="svelte-b9eyh1"&&(oe.innerHTML=Gt),rt=u(t),ne=s(t,"LI",{"data-svelte-h":!0}),a(ne)!=="svelte-1racnn8"&&(ne.textContent=Vt),t.forEach(i),He=u(e),A=s(e,"H3",{"data-svelte-h":!0}),a(A)!=="svelte-1e8h26s"&&(A.textContent=Kt),De=u(e),p=s(e,"OL",{});var w=m(p);R=s(w,"LI",{});var je=m(R);se=s(je,"P",{"data-svelte-h":!0}),a(se)!=="svelte-1j0b8q"&&(se.innerHTML=Yt),ut=u(je),le=s(je,"PRE",{class:!0});var si=m(le);Ee=Ne(si,!1),si.forEach(i),je.forEach(i),ct=u(w),ae=s(w,"LI",{"data-svelte-h":!0}),a(ae)!=="svelte-12gxy9s"&&(ae.innerHTML=Jt),dt=u(w),b=s(w,"LI",{});var pe=m(b);re=s(pe,"P",{"data-svelte-h":!0}),a(re)!=="svelte-1pprtuf"&&(re.innerHTML=$t),ht=u(pe),ue=s(pe,"OL",{"data-svelte-h":!0}),a(ue)!=="svelte-1sp0rtp"&&(ue.innerHTML=Xt),pt=u(pe),ce=s(pe,"PRE",{class:!0});var li=m(ce);Fe=Ne(li,!1),li.forEach(i),pe.forEach(i),mt=u(w),B=s(w,"LI",{});var Oe=m(B);de=s(Oe,"P",{"data-svelte-h":!0}),a(de)!=="svelte-1dqjk2n"&&(de.innerHTML=Zt),ft=u(Oe),he=s(Oe,"PRE",{class:!0});var ai=m(he);Pe=Ne(ai,!1),ai.forEach(i),Oe.forEach(i),w.forEach(i),Ae=u(e),Q=s(e,"H3",{"data-svelte-h":!0}),a(Q)!=="svelte-1xhr0p0"&&(Q.textContent=ei),Re=u(e),j=s(e,"P",{"data-svelte-h":!0}),a(j)!=="svelte-1li2iae"&&(j.innerHTML=ti),Be=u(e),O=s(e,"H3",{"data-svelte-h":!0}),a(O)!=="svelte-1dxnv6q"&&(O.textContent=ii),Qe=u(e),W=s(e,"P",{"data-svelte-h":!0}),a(W)!=="svelte-5up7mh"&&(W.innerHTML=oi),this.h()},h(){Me.a=null,y(Z,"class","language-undefined"),y(g,"href","https://hub.docker.com/_/microsoft-mssql-server"),y(g,"rel","nofollow"),y(v,"href","https://docs.liquibase.com/workflows/liquibase-community/using-liquibase-and-docker.html"),y(v,"rel","nofollow"),Ee.a=null,y(le,"class","language-c#"),Fe.a=null,y(ce,"class","language-c#"),Pe.a=null,y(he,"class","language-c#")},m(e,t){l(e,f,t),l(e,me,t),l(e,x,t),l(e,fe,t),l(e,C,t),l(e,be,t),l(e,q,t),l(e,ge,t),l(e,L,t),l(e,ve,t),l(e,T,t),l(e,we,t),l(e,_,t),l(e,ye,t),l(e,S,t),l(e,xe,t),l(e,k,t),l(e,Ce,t),l(e,I,t),l(e,qe,t),l(e,M,t),l(e,Le,t),l(e,H,t),l(e,Te,t),l(e,D,t),l(e,_e,t),l(e,E,t),l(e,Se,t),l(e,F,t),l(e,ke,t),l(e,P,t),l(e,Ie,t),l(e,c,t),o(c,U),o(c,ze),o(c,G),o(c,Ue),o(c,V),o(c,Ge),o(c,K),o(c,Ve),o(c,Y),o(c,Ke),o(c,J),o(c,Ye),o(c,$),o(c,Je),o(c,d),o(d,$e),o(d,X),o(d,Xe),o(d,Z),Me.m(ui,Z),o(d,Ze),o(d,g),o(d,et),o(d,v),o(d,tt),o(d,it),o(d,ot),o(d,ee),o(d,nt),o(c,st),o(c,te),o(c,lt),o(c,ie),o(c,at),o(c,oe),o(c,rt),o(c,ne),l(e,He,t),l(e,A,t),l(e,De,t),l(e,p,t),o(p,R),o(R,se),o(R,ut),o(R,le),Ee.m(ci,le),o(p,ct),o(p,ae),o(p,dt),o(p,b),o(b,re),o(b,ht),o(b,ue),o(b,pt),o(b,ce),Fe.m(di,ce),o(p,mt),o(p,B),o(B,de),o(B,ft),o(B,he),Pe.m(hi,he),l(e,Ae,t),l(e,Q,t),l(e,Re,t),l(e,j,t),l(e,Be,t),l(e,O,t),l(e,Qe,t),l(e,W,t)},p:bt,i:bt,o:bt,d(e){e&&(i(f),i(me),i(x),i(fe),i(C),i(be),i(q),i(ge),i(L),i(ve),i(T),i(we),i(_),i(ye),i(S),i(xe),i(k),i(Ce),i(I),i(qe),i(M),i(Le),i(H),i(Te),i(D),i(_e),i(E),i(Se),i(F),i(ke),i(P),i(Ie),i(c),i(He),i(A),i(De),i(p),i(Ae),i(Q),i(Re),i(j),i(Be),i(O),i(Qe),i(W))}}}class wi extends mi{constructor(f){super(),fi(this,f,null,bi,pi,{})}}export{wi as component};
